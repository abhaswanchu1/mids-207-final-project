{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Modeling Tweet classification with RNNs for Binary & Multiclass cases\n",
        "**Wendy Matta**"
      ],
      "metadata": {
        "id": "5uNPOvr7NaEn"
      },
      "id": "5uNPOvr7NaEn"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "afbe6fa4",
      "metadata": {
        "id": "afbe6fa4"
      },
      "outputs": [],
      "source": [
        "# %pip install numpy\n",
        "# %pip install scipy\n",
        "# %pip install tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# mount google drive\n",
        "USE_COLLAB = True\n",
        "\n",
        "if USE_COLLAB:\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/drive')\n",
        "  path_dir = 'drive/MyDrive/'\n",
        "else:\n",
        "  path_dir = ''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FWGhjYDNmN70",
        "outputId": "4a8a6f9f-a552-4888-ffaf-2e8fc828afd3"
      },
      "id": "FWGhjYDNmN70",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Binary Classification: Mental Health related vs. Normal"
      ],
      "metadata": {
        "id": "nAOWMQ8qNpWr"
      },
      "id": "nAOWMQ8qNpWr"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b38709ce",
      "metadata": {
        "id": "b38709ce"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import SimpleRNN, Dense, LSTM\n",
        "from scipy.sparse import load_npz\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import gc\n",
        "from sklearn.metrics import accuracy_score, f1_score as f1\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# random seed\n",
        "random.seed(42)\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Load the .npz files\n",
        "X_train = load_npz(path_dir+'X_train_bow.npz')\n",
        "X_train = X_train.astype(np.float32)  # Cast to float32\n",
        "X_val = load_npz(path_dir+'X_val_bow.npz')\n",
        "X_val = X_val.astype(np.float32)  # Cast to float32\n",
        "X_test = load_npz(path_dir+'X_test_bow.npz')\n",
        "X_test = X_test.astype(np.float32)  # Cast to float32\n",
        "\n",
        "# Load the .npy files\n",
        "y_train = np.load(path_dir+'y_train.npy')\n",
        "y_val = np.load(path_dir+'y_val.npy')\n",
        "y_test = np.load(path_dir+'y_test.npy')"
      ],
      "metadata": {
        "id": "8QQydFCBWrl1"
      },
      "id": "8QQydFCBWrl1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# sanity check\n",
        "assert X_train.shape[1] == X_val.shape[1] == X_test.shape[1]\n",
        "assert X_train.shape[0] > X_val.shape[0]\n",
        "assert X_train.shape[0] > X_test.shape[0]\n",
        "assert X_train.shape[0] == y_train.shape[0]"
      ],
      "metadata": {
        "id": "zkdzWB1BnfqT"
      },
      "id": "zkdzWB1BnfqT",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ETL"
      ],
      "metadata": {
        "id": "gfgoDg7yqUpW"
      },
      "id": "gfgoDg7yqUpW"
    },
    {
      "cell_type": "markdown",
      "source": [
        "We begin by turning our matrices into dense versions of themselves."
      ],
      "metadata": {
        "id": "oNzdTJ9BqsFd"
      },
      "id": "oNzdTJ9BqsFd"
    },
    {
      "cell_type": "code",
      "source": [
        "#Transform from sparse matrices to dense matrices b/c tf doesn't have a lot of support for modeling with sparse\n",
        "def transform_matrix(x): # For vanilla RNN\n",
        "    dense_matrix = x.toarray()\n",
        "    return dense_matrix.reshape((dense_matrix.shape[0], dense_matrix.shape[1], 1))\n",
        "\n",
        "def reshape_for_lstm(x): # for LSTM\n",
        "    dense = x.toarray()\n",
        "    # turn into float32\n",
        "    dense = dense.astype(np.float32)\n",
        "    return dense.reshape((dense.shape[0], 1, dense.shape[1]))"
      ],
      "metadata": {
        "id": "KZXJZt0EqrDH"
      },
      "id": "KZXJZt0EqrDH",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_lstm = reshape_for_lstm(X_train)\n",
        "X_val_lstm = reshape_for_lstm(X_val)\n",
        "X_test_lstm = reshape_for_lstm(X_test)\n",
        "\n",
        "#Reshape arrays to work better with tf\n",
        "y_train = y_train.reshape(-1, 1)\n",
        "y_val = y_val.reshape(-1, 1)\n",
        "y_test = y_test.reshape(-1, 1)\n",
        "print(y_train.shape)\n",
        "print(y_val.shape)\n",
        "print(y_test.shape)"
      ],
      "metadata": {
        "id": "yWhNbWw0qvM0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "02807f29-2378-45b7-b786-93b7e6878856"
      },
      "id": "yWhNbWw0qvM0",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(31608, 1)\n",
            "(10536, 1)\n",
            "(10537, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Changing token sizes"
      ],
      "metadata": {
        "id": "V8h-zkdf5YeQ"
      },
      "id": "V8h-zkdf5YeQ"
    },
    {
      "cell_type": "markdown",
      "source": [
        "We begin by reducing our dataset down to 500 tokens."
      ],
      "metadata": {
        "id": "QlCduwF_qc-M"
      },
      "id": "QlCduwF_qc-M"
    },
    {
      "cell_type": "code",
      "source": [
        "max_length = 500\n",
        "X_train = X_train[:, :max_length]\n",
        "X_val = X_val[:, :max_length]\n",
        "X_test = X_test[:, :max_length]"
      ],
      "metadata": {
        "id": "BhyKLx9XqXUR"
      },
      "id": "BhyKLx9XqXUR",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Given that we intend on training different RNN variants, we want to prepare the dataset in different ways, like transforming from sparse to dense matrices and reshaping them to be 3-dimensional, as in the case of an LSTM:"
      ],
      "metadata": {
        "id": "aCIEBDRNopeO"
      },
      "id": "aCIEBDRNopeO"
    },
    {
      "cell_type": "markdown",
      "source": [
        "However, our labels / response variables don't need specialized transformation:"
      ],
      "metadata": {
        "id": "rnU-a8VDoyqx"
      },
      "id": "rnU-a8VDoyqx"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LSTM Model"
      ],
      "metadata": {
        "id": "X6_Vovr1nLxR"
      },
      "id": "X6_Vovr1nLxR"
    },
    {
      "cell_type": "code",
      "source": [
        "def build_lstm(X_train, y_train, X_val, y_val, truncate_to: int = 40000):\n",
        "\n",
        "  # Clear any TensorFlow session\n",
        "  tf.keras.backend.clear_session()\n",
        "  # Garbage collect objects no longer in use\n",
        "  gc.collect()\n",
        "\n",
        "  model = Sequential()\n",
        "\n",
        "  # Add an LSTM layer\n",
        "  model.add(LSTM(units=50, activation='relu', input_shape=(X_train.shape[1], X_train.shape[2])))\n",
        "\n",
        "  # Add a Dense output layer (e.g., for binary classification)\n",
        "  model.add(Dense(1, activation='sigmoid'))  # Use sigmoid for binary classification\n",
        "\n",
        "  # Compile the model\n",
        "  model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "  # Step 6: Train the model\n",
        "  model.fit(\n",
        "      X_train,\n",
        "      y_train,\n",
        "      epochs=5, #number of cycles\n",
        "      batch_size=16, #number of samples processed at a time\n",
        "      validation_data=(X_val, y_val),\n",
        "      callbacks=[\n",
        "          EarlyStopping(monitor='val_loss', patience=2, restore_best_weights=True)\n",
        "        ]\n",
        "  )\n",
        "\n",
        "  # Step 6.5: Add Early Stopping\n",
        "\n",
        "\n",
        "  # Step 7: Evaluate the model\n",
        "  loss, accuracy = model.evaluate(X_val, y_val)\n",
        "  print(f'Validation loss: {loss}, Validation accuracy: {accuracy}')\n",
        "\n",
        "  # Step 8: Make predictions\n",
        "  predictions = model.predict(X_val)\n",
        "  print(predictions)\n",
        "\n",
        "  return {\n",
        "      'predictions': predictions,\n",
        "      'model': model,\n",
        "      'loss': loss,\n",
        "      'accuracy': accuracy\n",
        "  }"
      ],
      "metadata": {
        "id": "3iOe72iunPAi"
      },
      "id": "3iOe72iunPAi",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = build_lstm(X_train_lstm, y_train, X_val_lstm, y_val)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Udl627LZ6Eow",
        "outputId": "c6930dcc-f988-424d-b46a-048e1f1a3451"
      },
      "id": "Udl627LZ6Eow",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1976/1976 [==============================] - 99s 49ms/step - loss: 0.1961 - accuracy: 0.9251 - val_loss: 0.1395 - val_accuracy: 0.9502\n",
            "Epoch 2/5\n",
            "1976/1976 [==============================] - 95s 48ms/step - loss: 0.0857 - accuracy: 0.9689 - val_loss: 0.1520 - val_accuracy: 0.9473\n",
            "Epoch 3/5\n",
            "1976/1976 [==============================] - 94s 48ms/step - loss: 0.0506 - accuracy: 0.9823 - val_loss: 0.1818 - val_accuracy: 0.9484\n",
            "330/330 [==============================] - 2s 5ms/step - loss: 0.1395 - accuracy: 0.9502\n",
            "Validation loss: 0.13945114612579346, Validation accuracy: 0.9501708149909973\n",
            "330/330 [==============================] - 2s 5ms/step\n",
            "[[0.99999946]\n",
            " [0.3109116 ]\n",
            " [0.9802329 ]\n",
            " ...\n",
            " [0.8580782 ]\n",
            " [0.99998486]\n",
            " [0.04035855]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6ea2eba1",
      "metadata": {
        "id": "6ea2eba1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8271d0ff-6dd9-4158-d996-a4a56786536a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "330/330 [==============================] - 2s 5ms/step\n",
            "Accuracy: 0.9474233652842365\n",
            "F1 Score: 0.9616024397005822\n"
          ]
        }
      ],
      "source": [
        "# run model against test data and get accuracy and F1 score\n",
        "# get predictions\n",
        "model = model['model']\n",
        "predictions = model.predict(X_test_lstm)\n",
        "\n",
        "# get accuracy and f1 score from predictions\n",
        "accuracy = accuracy_score(y_test, predictions.round())\n",
        "f1_score = f1(y_test, predictions.round())\n",
        "\n",
        "print(f'Accuracy: {accuracy}')\n",
        "print(f'F1 Score: {f1_score}')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Our model generalizes well to the testing data with an accuracy of ~95% and an F1 score of %96."
      ],
      "metadata": {
        "id": "vWITkDlZQ4qF"
      },
      "id": "vWITkDlZQ4qF"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Multiclass Modeling for Tweets"
      ],
      "metadata": {
        "id": "bTw4g8PSQzYe"
      },
      "id": "bTw4g8PSQzYe"
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, we read in our multi class labels:"
      ],
      "metadata": {
        "id": "15cmcsp_TdWb"
      },
      "id": "15cmcsp_TdWb"
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the .npy files\n",
        "NUM_CLASSES = 7\n",
        "\n",
        "y_train = np.load(path_dir+'y_train_multi.npy')\n",
        "y_val = np.load(path_dir+'y_val_multi.npy')\n",
        "y_test = np.load(path_dir+'y_test_multi.npy')"
      ],
      "metadata": {
        "id": "BSE4CXhETcxU"
      },
      "id": "BSE4CXhETcxU",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# sanity check, as a treat\n",
        "print(y_train.shape)\n",
        "print(y_val.shape)\n",
        "print(y_test.shape)\n",
        "\n",
        "# our labels should have 7 different classes\n",
        "assert len(np.unique(y_train)) == NUM_CLASSES\n",
        "assert len(np.unique(y_val)) == NUM_CLASSES\n",
        "assert len(np.unique(y_test)) == NUM_CLASSES"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oyi_oglFTmHH",
        "outputId": "eb6e38f6-3f61-490a-94d4-595f9810be29"
      },
      "id": "Oyi_oglFTmHH",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(31608,)\n",
            "(10536,)\n",
            "(10537,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# convert to one-hot encoding\n",
        "y_train = to_categorical(y_train, num_classes=NUM_CLASSES)\n",
        "y_val = to_categorical(y_val, num_classes=NUM_CLASSES)\n",
        "y_test = to_categorical(y_test, num_classes=NUM_CLASSES)"
      ],
      "metadata": {
        "id": "Y2hC1EhgVLTn"
      },
      "id": "Y2hC1EhgVLTn",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, we begin by creating a multiclass LSTM model that has multiple output nodes:"
      ],
      "metadata": {
        "id": "PvY92x3PTVP1"
      },
      "id": "PvY92x3PTVP1"
    },
    {
      "cell_type": "code",
      "source": [
        "def build_lstm_multi(X_train, y_train, X_val, y_val, truncate_to: int = 40000):\n",
        "\n",
        "  # Clear any TensorFlow session\n",
        "  tf.keras.backend.clear_session()\n",
        "  # Garbage collect objects no longer in use\n",
        "  gc.collect()\n",
        "\n",
        "  model = Sequential()\n",
        "\n",
        "  # Add an LSTM layer\n",
        "  model.add(LSTM(units=50, activation='relu', input_shape=(X_train.shape[1], X_train.shape[2])))\n",
        "\n",
        "  # Add a Dense output layer (e.g., for binary classification)\n",
        "  model.add(Dense(NUM_CLASSES, activation='softmax'))\n",
        "\n",
        "  # Compile the model\n",
        "  model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "  # Step 6: Train the model\n",
        "  model.fit(\n",
        "      X_train,\n",
        "      y_train,\n",
        "      epochs=5, #number of cycles\n",
        "      batch_size=16, #number of samples processed at a time\n",
        "      validation_data=(X_val, y_val),\n",
        "      callbacks=[\n",
        "          EarlyStopping(monitor='val_loss', patience=2, restore_best_weights=True)\n",
        "        ]\n",
        "  )\n",
        "\n",
        "  # Step 6.5: Add Early Stopping\n",
        "\n",
        "\n",
        "  # Step 7: Evaluate the model\n",
        "  loss, accuracy = model.evaluate(X_val, y_val)\n",
        "  print(f'Validation loss: {loss}, Validation accuracy: {accuracy}')\n",
        "\n",
        "  # Step 8: Make predictions\n",
        "  predictions = model.predict(X_val)\n",
        "  print(predictions)\n",
        "\n",
        "  return {\n",
        "      'predictions': predictions,\n",
        "      'model': model,\n",
        "      'loss': loss,\n",
        "      'accuracy': accuracy\n",
        "  }"
      ],
      "metadata": {
        "id": "Anu3NyI6QxqF"
      },
      "id": "Anu3NyI6QxqF",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = build_lstm_multi(X_train_lstm, y_train, X_val_lstm, y_val)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w2voJLH_VcbW",
        "outputId": "9b920a77-a2a8-4691-f487-6ffec8c3b8c2"
      },
      "id": "w2voJLH_VcbW",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1976/1976 [==============================] - 100s 50ms/step - loss: 0.8912 - accuracy: 0.6931 - val_loss: 0.6851 - val_accuracy: 0.7469\n",
            "Epoch 2/5\n",
            "1976/1976 [==============================] - 97s 49ms/step - loss: 0.4304 - accuracy: 0.8452 - val_loss: 0.6581 - val_accuracy: 0.7705\n",
            "Epoch 3/5\n",
            "1976/1976 [==============================] - 96s 48ms/step - loss: 0.2535 - accuracy: 0.9119 - val_loss: 0.7685 - val_accuracy: 0.7594\n",
            "Epoch 4/5\n",
            "1976/1976 [==============================] - 96s 48ms/step - loss: 0.1716 - accuracy: 0.9468 - val_loss: 0.8961 - val_accuracy: 0.7555\n",
            "330/330 [==============================] - 2s 5ms/step - loss: 0.6581 - accuracy: 0.7705\n",
            "Validation loss: 0.658083438873291, Validation accuracy: 0.7705011367797852\n",
            "330/330 [==============================] - 2s 5ms/step\n",
            "[[3.24647466e-04 4.29613516e-03 7.29089677e-01 ... 4.57335413e-02\n",
            "  1.14877336e-03 2.19407141e-01]\n",
            " [1.48954997e-02 3.95857496e-03 1.06858590e-03 ... 1.49605144e-02\n",
            "  4.10000294e-01 1.99537426e-05]\n",
            " [3.56217526e-04 6.69010682e-04 4.92762960e-03 ... 6.79569726e-04\n",
            "  9.91446078e-01 1.52989035e-03]\n",
            " ...\n",
            " [2.29061581e-02 1.80740021e-02 1.80418700e-01 ... 4.00814414e-02\n",
            "  3.64792831e-02 5.42077482e-01]\n",
            " [9.24810651e-04 3.49389715e-03 1.36335582e-01 ... 2.28603673e-03\n",
            "  6.75614574e-04 8.56282949e-01]\n",
            " [2.35881377e-03 6.92092581e-04 1.09584145e-02 ... 7.75438093e-04\n",
            "  2.25055544e-03 2.26997957e-02]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# run model against test data and get accuracy and F1 score\n",
        "# get predictions\n",
        "model = model['model']\n",
        "predictions = model.predict(X_test_lstm)\n",
        "\n",
        "# get accuracy and f1 score from predictions\n",
        "accuracy = accuracy_score(y_test, predictions.round())\n",
        "f1_score = f1(y_test, predictions.round(), average='weighted')\n",
        "\n",
        "print(f'Accuracy: {accuracy}')\n",
        "print(f'F1 Score: {f1_score}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A4d5aQljVha6",
        "outputId": "f79dd9bb-943c-47d6-ea0c-d1a65137f795"
      },
      "id": "A4d5aQljVha6",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "330/330 [==============================] - 2s 5ms/step\n",
            "Accuracy: 0.7322767391098035\n",
            "F1 Score: 0.7576816517319498\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V28"
    },
    "accelerator": "TPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}